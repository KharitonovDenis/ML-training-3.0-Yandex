{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Переобучение нейронных сетей и борьба с ним\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqXwLbu6Ifa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QMvEbquQ6Ifd"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "def args_and_kwargs(*args, **kwargs):\n",
        "    return args, kwargs\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        layer_info = {\"type\": layer_name.strip()}\n",
        "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
        "\n",
        "        param_dict = {}\n",
        "        if len(params):\n",
        "            args, kwargs = eval(params_template)\n",
        "            if len(args) or len(kwargs):\n",
        "                param_dict[\"args\"] = args\n",
        "                for name, value in kwargs.items():\n",
        "                    param_dict[name] = value\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "def parse_pytorch_model_FIX(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        params = params.rstrip(\")\")\n",
        "        layer_info[\"type\"] = layer_name.strip()\n",
        "        param_dict = {}\n",
        "        tmp = ''\n",
        "        for param in params.split(\", \"):\n",
        "            if \"=\" in param or tmp:                \n",
        "                if tmp:\n",
        "                    if ')' in param:\n",
        "                        value = tmp + ',' + param                \n",
        "                        tmp = ''\n",
        "                    else:\n",
        "                        tmp = tmp + ', ' + param\n",
        "                        continue\n",
        "                else:\n",
        "                    key, value = param.split(\"=\")\n",
        "                    if '(' in value:\n",
        "                        tmp = value\n",
        "                        continue\n",
        "                param_dict[key.strip()] = eval(value.strip())\n",
        "\n",
        "            else:\n",
        "                param_dict[param.strip()] = None\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict"
      ],
      "metadata": {
        "id": "VZ1rQHzepBVo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zfmFybmq6Ife"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWCrcOj26Iff"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5cFoNcE6Ifg",
        "outputId": "d38b6fb2-c563-4102-e9b3-f1fb8ad01915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-23 17:34:30--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-23 17:34:31--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-23 17:34:31 (321 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "szX6rWNI6Ifh"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
        "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
        "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t1wYZvwm6Ifi"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "12a32a8e-9e09-44b9-f534-88421b95b097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 3')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_1 = nn.Sequential(nn.Conv2d(1, 15, 3, padding=1), # 28*28\n",
        "                             nn.MaxPool2d(kernel_size=2), # 14*14\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Conv2d(15, 15, 3, padding=1), # 14*14\n",
        "                             nn.MaxPool2d(kernel_size=2), # 7*7\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Conv2d(15, 15, 1, padding=0), # 7*7 # padding=0 было\n",
        "                             nn.SiLU(),\n",
        "                             nn.Flatten(),\n",
        "                             nn.Linear(7 * 7 * 15, 10),\n",
        "                             #nn.SiLU(),\n",
        "                             #nn.Linear(100, 10)\n",
        "                             )\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4d91c7-fc93-4d7e-d78e-24fce257b616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (2): SiLU()\n",
              "  (3): Conv2d(15, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): SiLU()\n",
              "  (6): Conv2d(15, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (7): SiLU()\n",
              "  (8): Flatten(start_dim=1, end_dim=-1)\n",
              "  (9): Linear(in_features=735, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "a77866f6-22a3-4e2b-bced-bc69c17a15a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [],
      "source": [
        "# your code here\n",
        "crit = nn.CrossEntropyLoss()\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.Adam\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs, crit, lr, optimizer):\n",
        "    opt = optimizer(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        mean_train_loss = 0\n",
        "        mean_train_acc = 0\n",
        "        for X, label in train_data_loader:\n",
        "\n",
        "            X, label = X.to(device), label.to(device)\n",
        "            opt.zero_grad()\n",
        "            output = model(X)\n",
        "            loss = crit(output, label)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            with torch.no_grad():\n",
        "                mean_train_loss += loss\n",
        "                mean_train_acc += torch.sum(torch.argmax(output, dim=1) == label, dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            mean_train_loss /= float(len(train_data_loader))\n",
        "            mean_train_acc /= float(len(train_fmnist_data))\n",
        "\n",
        "        model.eval()\n",
        "        mean_test_loss = 0\n",
        "        mean_test_acc = 0\n",
        "        with torch.no_grad():\n",
        "            for X, label in test_data_loader:\n",
        "                X, label = X.to(device), label.to(device)\n",
        "                output = model(X)\n",
        "                loss = crit(output, label)\n",
        "                mean_test_loss += loss\n",
        "                mean_test_acc += torch.sum(torch.argmax(output, dim=1) == label, dtype=torch.float32)\n",
        "            mean_test_loss /= len(test_data_loader)\n",
        "            mean_test_acc /= len(test_fmnist_data)\n",
        "        print(f'Epoch {epoch + 1} from {epochs}. \\n Train loss: {mean_train_loss} \\n Train accuracy: {mean_train_acc} \\n Test loss: {mean_test_loss} \\n Test accuracy: {mean_test_acc}')\n",
        "    return model, opt"
      ],
      "metadata": {
        "id": "nnhUHYqo62kR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_1, _ = train(model_task_1, epochs, crit, lr, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY1nZcmE-M58",
        "outputId": "aff7012a-f91f-4bdc-93ff-9e05598edd50",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 from 10. \n",
            " Train loss: 0.551845908164978 \n",
            " Train accuracy: 0.7986500263214111 \n",
            " Test loss: 0.41525521874427795 \n",
            " Test accuracy: 0.8496999740600586\n",
            "Epoch 2 from 10. \n",
            " Train loss: 0.36219748854637146 \n",
            " Train accuracy: 0.8699333667755127 \n",
            " Test loss: 0.360680490732193 \n",
            " Test accuracy: 0.8718999624252319\n",
            "Epoch 3 from 10. \n",
            " Train loss: 0.3186100423336029 \n",
            " Train accuracy: 0.8860166668891907 \n",
            " Test loss: 0.32657089829444885 \n",
            " Test accuracy: 0.8811999559402466\n",
            "Epoch 4 from 10. \n",
            " Train loss: 0.2948113679885864 \n",
            " Train accuracy: 0.8933833241462708 \n",
            " Test loss: 0.3122061789035797 \n",
            " Test accuracy: 0.8892999887466431\n",
            "Epoch 5 from 10. \n",
            " Train loss: 0.2763672173023224 \n",
            " Train accuracy: 0.9002833366394043 \n",
            " Test loss: 0.3313828110694885 \n",
            " Test accuracy: 0.8797000050544739\n",
            "Epoch 6 from 10. \n",
            " Train loss: 0.264178603887558 \n",
            " Train accuracy: 0.9038000106811523 \n",
            " Test loss: 0.30076777935028076 \n",
            " Test accuracy: 0.8901000022888184\n",
            "Epoch 7 from 10. \n",
            " Train loss: 0.2540232241153717 \n",
            " Train accuracy: 0.9078166484832764 \n",
            " Test loss: 0.3040289282798767 \n",
            " Test accuracy: 0.8876999616622925\n",
            "Epoch 8 from 10. \n",
            " Train loss: 0.2445361167192459 \n",
            " Train accuracy: 0.910016655921936 \n",
            " Test loss: 0.28018882870674133 \n",
            " Test accuracy: 0.9006999731063843\n",
            "Epoch 9 from 10. \n",
            " Train loss: 0.2389293760061264 \n",
            " Train accuracy: 0.9130666851997375 \n",
            " Test loss: 0.29952847957611084 \n",
            " Test accuracy: 0.8912000060081482\n",
            "Epoch 10 from 10. \n",
            " Train loss: 0.23209530115127563 \n",
            " Train accuracy: 0.9143833518028259 \n",
            " Test loss: 0.30832743644714355 \n",
            " Test accuracy: 0.8941999673843384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e3d60a-9b89-4660-ccb4-3f1f2f1c46d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.91127\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cd3ebe-a7fc-4130-f967-cec99e3f74cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8942\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXQlXWwo6Ifn"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import re\n",
        "import ast\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_info = {}\n",
        "        parts = layer_str.split(\"(\", 1)\n",
        "        layer_name = parts[0].strip()\n",
        "        layer_info[\"type\"] = layer_name\n",
        "        \n",
        "        if len(parts) == 1:\n",
        "            layer_info[\"parameters\"] = {}\n",
        "            return layer_info\n",
        "            \n",
        "        params_str = parts[1].rstrip(\")\")\n",
        "        param_dict = {}\n",
        "        current_param = []\n",
        "        in_brackets = 0\n",
        "        \n",
        "        for char in params_str + \",\":\n",
        "            if char == \"(\":\n",
        "                in_brackets += 1\n",
        "                current_param.append(char)\n",
        "            elif char == \")\":\n",
        "                in_brackets -= 1\n",
        "                current_param.append(char)\n",
        "            elif char == \",\" and in_brackets == 0:\n",
        "                param = \"\".join(current_param).strip()\n",
        "                if param:\n",
        "                    if \"=\" in param:\n",
        "                        key, value = param.split(\"=\", 1)\n",
        "                        key = key.strip()\n",
        "                        value = value.strip()\n",
        "                        try:\n",
        "                            param_dict[key] = ast.literal_eval(value)\n",
        "                        except:\n",
        "                            param_dict[key] = value\n",
        "                    else:\n",
        "                        param_dict[param] = None\n",
        "                current_param = []\n",
        "            else:\n",
        "                current_param.append(char)\n",
        "        \n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    # Обработка входных данных\n",
        "    lines = [line.strip() for line in model_str.splitlines() if line.strip()]\n",
        "    if not lines:\n",
        "        return {\"model_name\": \"Unknown\", \"layers\": []}\n",
        "\n",
        "    # Извлекаем имя модели из первой строки (новый способ)\n",
        "    model_name = lines[0].split(\"(\", 1)[0].strip()\n",
        "    model_dict = {\n",
        "        \"model_name\": model_name,\n",
        "        \"layers\": []\n",
        "    }\n",
        "\n",
        "    # Регулярное выражение для слоев\n",
        "    layer_pattern = re.compile(r\"\\((\\w+)\\):\\s*(\\w+)\\((.*)\\)\")\n",
        "    \n",
        "    for line in lines[1:]:\n",
        "        if line.startswith(\"(\") and \"):\" in line:\n",
        "            match = layer_pattern.match(line)\n",
        "            if match:\n",
        "                layer_name, layer_type, params = match.groups()\n",
        "                try:\n",
        "                    layer_info = parse_layer(f\"{layer_type}({params})\")\n",
        "                    model_dict[\"layers\"].append({\n",
        "                        \"name\": layer_name,\n",
        "                        \"type\": layer_type,\n",
        "                        \"parameters\": layer_info[\"parameters\"]\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing layer {layer_name}: {str(e)}\")\n",
        "\n",
        "    return model_dict"
      ],
      "metadata": {
        "id": "V-OxGXUyp2kf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcs4sJUn6Ifn",
        "outputId": "dea98221-5e90-4b31-ce61-8f317552a979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5QH1wsg6Ifn"
      },
      "source": [
        "### Задача №2: Переобучение (Initiation)\n",
        "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
        "\n",
        "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
        "\n",
        "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9pAvMpy6Ifn"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче.\n",
        "\n",
        "Не используйте `Dropout` и `BatchNorm` в этой задаче"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZuW4GkCz6Ifo"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_2 = nn.Sequential(nn.Conv2d(1, 20, 3, padding=1), # 28*28\n",
        "                             nn.MaxPool2d(kernel_size=2), # 14*14\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Conv2d(20, 20, 3, padding=1), # 14*14\n",
        "                             nn.SiLU(),\n",
        "                             nn.Conv2d(20, 20, 3, padding=1),\n",
        "                             nn.MaxPool2d(kernel_size=2), # 7*7\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Conv2d(20, 15, 1, padding=0), # 7*7\n",
        "                             nn.SiLU(),\n",
        "                             nn.Flatten(),\n",
        "                             nn.Linear(7 * 7 * 15, 50),\n",
        "                             nn.SiLU(),\n",
        "                             nn.Linear(50, 10)\n",
        "                             #nn.SiLU(),\n",
        "                             #nn.Linear(100, 10)\n",
        "                             )\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOnCO9VAl-It",
        "outputId": "c3331677-5b9e-4a04-f398-e556135662ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (2): SiLU()\n",
              "  (3): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): SiLU()\n",
              "  (5): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (7): SiLU()\n",
              "  (8): Conv2d(20, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (9): SiLU()\n",
              "  (10): Flatten(start_dim=1, end_dim=-1)\n",
              "  (11): Linear(in_features=735, out_features=50, bias=True)\n",
              "  (12): SiLU()\n",
              "  (13): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FTHNn0Ae6Ifo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3764d2-b9db-4c65-e910-85dabec4f5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 from 20. \n",
            " Train loss: 0.5340753197669983 \n",
            " Train accuracy: 0.8020833134651184 \n",
            " Test loss: 0.38727426528930664 \n",
            " Test accuracy: 0.8590999841690063\n",
            "Epoch 2 from 20. \n",
            " Train loss: 0.3315041959285736 \n",
            " Train accuracy: 0.8765833377838135 \n",
            " Test loss: 0.31963950395584106 \n",
            " Test accuracy: 0.8801999688148499\n",
            "Epoch 3 from 20. \n",
            " Train loss: 0.28271645307540894 \n",
            " Train accuracy: 0.8943333625793457 \n",
            " Test loss: 0.2998596429824829 \n",
            " Test accuracy: 0.8883999586105347\n",
            "Epoch 4 from 20. \n",
            " Train loss: 0.24888809025287628 \n",
            " Train accuracy: 0.9070667028427124 \n",
            " Test loss: 0.28750181198120117 \n",
            " Test accuracy: 0.8937999606132507\n",
            "Epoch 5 from 20. \n",
            " Train loss: 0.22664637863636017 \n",
            " Train accuracy: 0.9149667024612427 \n",
            " Test loss: 0.2728121876716614 \n",
            " Test accuracy: 0.9009999632835388\n",
            "Epoch 6 from 20. \n",
            " Train loss: 0.20706142485141754 \n",
            " Train accuracy: 0.923216700553894 \n",
            " Test loss: 0.24775025248527527 \n",
            " Test accuracy: 0.9121999740600586\n",
            "Epoch 7 from 20. \n",
            " Train loss: 0.190914586186409 \n",
            " Train accuracy: 0.9277166724205017 \n",
            " Test loss: 0.25244006514549255 \n",
            " Test accuracy: 0.9080999493598938\n",
            "Epoch 8 from 20. \n",
            " Train loss: 0.1760300248861313 \n",
            " Train accuracy: 0.9343000054359436 \n",
            " Test loss: 0.2597324550151825 \n",
            " Test accuracy: 0.9108999967575073\n",
            "Epoch 9 from 20. \n",
            " Train loss: 0.1621694713830948 \n",
            " Train accuracy: 0.9390333294868469 \n",
            " Test loss: 0.2605348229408264 \n",
            " Test accuracy: 0.9101999998092651\n",
            "Epoch 10 from 20. \n",
            " Train loss: 0.14983342587947845 \n",
            " Train accuracy: 0.9431999921798706 \n",
            " Test loss: 0.2613360285758972 \n",
            " Test accuracy: 0.9145999550819397\n",
            "Epoch 11 from 20. \n",
            " Train loss: 0.139276921749115 \n",
            " Train accuracy: 0.9477166533470154 \n",
            " Test loss: 0.27918142080307007 \n",
            " Test accuracy: 0.9067999720573425\n",
            "Epoch 12 from 20. \n",
            " Train loss: 0.1304696500301361 \n",
            " Train accuracy: 0.950950026512146 \n",
            " Test loss: 0.29440832138061523 \n",
            " Test accuracy: 0.9080999493598938\n",
            "Epoch 13 from 20. \n",
            " Train loss: 0.1201360672712326 \n",
            " Train accuracy: 0.9540500044822693 \n",
            " Test loss: 0.295014351606369 \n",
            " Test accuracy: 0.9108999967575073\n",
            "Epoch 14 from 20. \n",
            " Train loss: 0.11316496878862381 \n",
            " Train accuracy: 0.9570167064666748 \n",
            " Test loss: 0.2855302095413208 \n",
            " Test accuracy: 0.913100004196167\n",
            "Epoch 15 from 20. \n",
            " Train loss: 0.10326220840215683 \n",
            " Train accuracy: 0.9611666798591614 \n",
            " Test loss: 0.2998868525028229 \n",
            " Test accuracy: 0.9122999906539917\n",
            "Epoch 16 from 20. \n",
            " Train loss: 0.09650211036205292 \n",
            " Train accuracy: 0.9636499881744385 \n",
            " Test loss: 0.3123069405555725 \n",
            " Test accuracy: 0.9145999550819397\n",
            "Epoch 17 from 20. \n",
            " Train loss: 0.09069594740867615 \n",
            " Train accuracy: 0.966866672039032 \n",
            " Test loss: 0.32914841175079346 \n",
            " Test accuracy: 0.9074999690055847\n",
            "Epoch 18 from 20. \n",
            " Train loss: 0.08367877453565598 \n",
            " Train accuracy: 0.9685166478157043 \n",
            " Test loss: 0.35775983333587646 \n",
            " Test accuracy: 0.91239994764328\n",
            "Epoch 19 from 20. \n",
            " Train loss: 0.07865054160356522 \n",
            " Train accuracy: 0.9702333211898804 \n",
            " Test loss: 0.37198856472969055 \n",
            " Test accuracy: 0.9077999591827393\n",
            "Epoch 20 from 20. \n",
            " Train loss: 0.07322098314762115 \n",
            " Train accuracy: 0.9723833203315735 \n",
            " Test loss: 0.3876660168170929 \n",
            " Test accuracy: 0.9122999906539917\n"
          ]
        }
      ],
      "source": [
        "model_task_2, _ = train(model_task_2, 20, crit, lr, optimizer)# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI5e7c4q6Ifo"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aHpIzqny6Ifo"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_2 = []\n",
        "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
        "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
        "    layers_task_2.append(layer_name)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgOMnmWz6Ifp"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vtMe5mC26Ifp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc7259a-b5a7-4189-a08f-bc9bde666492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.9783\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kS5lL4Ki6Ifp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c95b92-eea3-4faf-d274-1e5c1624ad10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9123\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg570GsS6Ifp"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k2T6vVgL6Ifp"
      },
      "outputs": [],
      "source": [
        "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
        "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert (\n",
        "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
        "), \"Test accuracy should be at least 0.04 lower that train.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XLojhiY6Ifr"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NwMxXcgC6Ifr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb536e5-8f54-4971-e87c-d4bb288aa1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_tasks_1_and_2.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTUtxof96Ifr"
      },
      "source": [
        "### Задача №3: Исправление модели (Return)\n",
        "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
        "\n",
        "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
        "\n",
        "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKjGC3D_6Ifr"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче.\n",
        "\n",
        "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WSo4ilCC6Ifs"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert (\n",
        "    layers_task_2 is not None\n",
        "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wy7pSbPm6Ifs"
      },
      "outputs": [],
      "source": [
        "model_task_3 = nn.Sequential(nn.Conv2d(1, 20, 3, padding=1), # 28*28\n",
        "                             nn.MaxPool2d(kernel_size=2), # 14*14\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Dropout(p=0.3),\n",
        "\n",
        "                             nn.Conv2d(20, 20, 3, padding=1), # 14*14\n",
        "                             nn.SiLU(),\n",
        "                             nn.Conv2d(20, 20, 3, padding=1),\n",
        "                             nn.MaxPool2d(kernel_size=2), # 7*7\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Conv2d(20, 15, 1, padding=0), # 7*7\n",
        "                             nn.SiLU(),\n",
        "\n",
        "                             nn.Dropout(),\n",
        "\n",
        "                             nn.Flatten(),\n",
        "                             nn.Linear(7 * 7 * 15, 50),\n",
        "                             nn.SiLU(),\n",
        "                             nn.Linear(50, 10)\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_3.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amfkjtmsw9f8",
        "outputId": "b3c132bf-458d-4af4-e6f2-98a773b176a9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (2): SiLU()\n",
              "  (3): Dropout(p=0.3, inplace=False)\n",
              "  (4): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (5): SiLU()\n",
              "  (6): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (8): SiLU()\n",
              "  (9): Conv2d(20, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (10): SiLU()\n",
              "  (11): Dropout(p=0.5, inplace=False)\n",
              "  (12): Flatten(start_dim=1, end_dim=-1)\n",
              "  (13): Linear(in_features=735, out_features=50, bias=True)\n",
              "  (14): SiLU()\n",
              "  (15): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iaTa_pLe6Ifs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50557dbc-49d6-45a8-f136-499180598702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 from 6. \n",
            " Train loss: 0.6270601153373718 \n",
            " Train accuracy: 0.7618833184242249 \n",
            " Test loss: 0.4215855598449707 \n",
            " Test accuracy: 0.8427000045776367\n",
            "Epoch 2 from 6. \n",
            " Train loss: 0.41880059242248535 \n",
            " Train accuracy: 0.8426833152770996 \n",
            " Test loss: 0.36782389879226685 \n",
            " Test accuracy: 0.8606999516487122\n",
            "Epoch 3 from 6. \n",
            " Train loss: 0.3664586842060089 \n",
            " Train accuracy: 0.860966682434082 \n",
            " Test loss: 0.32269933819770813 \n",
            " Test accuracy: 0.8787999749183655\n",
            "Epoch 4 from 6. \n",
            " Train loss: 0.3383193016052246 \n",
            " Train accuracy: 0.8736667037010193 \n",
            " Test loss: 0.30514195561408997 \n",
            " Test accuracy: 0.8870999813079834\n",
            "Epoch 5 from 6. \n",
            " Train loss: 0.3142194449901581 \n",
            " Train accuracy: 0.8828666806221008 \n",
            " Test loss: 0.2892489731311798 \n",
            " Test accuracy: 0.8946999907493591\n",
            "Epoch 6 from 6. \n",
            " Train loss: 0.30057090520858765 \n",
            " Train accuracy: 0.8871999979019165 \n",
            " Test loss: 0.2713561952114105 \n",
            " Test accuracy: 0.9001999497413635\n"
          ]
        }
      ],
      "source": [
        "model_task_3, _ = train(model=model_task_3, epochs=6, crit=crit, lr=lr, optimizer=optimizer) # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPjZn0Ta6Ifs"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GtBnyKw86Ifs"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_3 = []\n",
        "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    layers_task_3.append(layer_name)\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for model_3_layer in layers_task_3:\n",
        "    model_2_layer = layers_task_2[idx]\n",
        "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
        "        assert (\n",
        "            model_3_layer == model_2_layer\n",
        "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
        "        idx += 1\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1MouP7r6Ift"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "2g1SsGXT6Ift",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416cf497-842e-4fde-a5ac-c87f6a4cf21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.91337\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_yebrbjd6Ift",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc59080-4fea-4242-8c83-5bfa18ec5687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9002\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hTHUqT-6Ifu"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "599u9kQq6Ifu"
      },
      "outputs": [],
      "source": [
        "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
        "assert (\n",
        "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
        "), \"Test accuracy should not be lower that train more than by 0.015\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYOZkeQ86Ifu"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kmIA_wLq6Ifu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b29d54-62de-4b1d-ed58-7b5e88f8439a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_final.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_final.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xai8JL3tgSq_"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
        "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
        "* `submission_dict_final.json` в задачу Return.\n",
        "\n",
        "\n",
        "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}